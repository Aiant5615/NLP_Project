{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device(\"mps\")\n",
    "torch.manual_seed(777)\n",
    "if device == 'mps':\n",
    "    torch.mps.manual_seed_all(777)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이토치로 단층 퍼셉트론 구현하기\n",
    "X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]]).to(device)\n",
    "Y = torch.FloatTensor([[0], [1], [1], [0]]).to(device)\n",
    "\n",
    "linear = nn.Linear(2, 1, bias=True)\n",
    "sigmoid = nn.Sigmoid()\n",
    "model = nn.Sequential(linear, sigmoid).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7273974418640137\n",
      "100 0.6931475400924683\n",
      "200 0.6931471228599548\n",
      "300 0.6931471228599548\n",
      "400 0.6931471824645996\n",
      "500 0.6931471824645996\n",
      "600 0.6931471824645996\n",
      "700 0.6931471824645996\n",
      "800 0.6931471824645996\n",
      "900 0.6931471824645996\n",
      "1000 0.6931471824645996\n",
      "1100 0.6931471824645996\n",
      "1200 0.6931471824645996\n",
      "1300 0.6931471824645996\n",
      "1400 0.6931471824645996\n",
      "1500 0.6931471824645996\n",
      "1600 0.6931471824645996\n",
      "1700 0.6931471824645996\n",
      "1800 0.6931471824645996\n",
      "1900 0.6931471824645996\n",
      "2000 0.6931471824645996\n",
      "2100 0.6931471824645996\n",
      "2200 0.6931471824645996\n",
      "2300 0.6931471824645996\n",
      "2400 0.6931471824645996\n",
      "2500 0.6931471824645996\n",
      "2600 0.6931471824645996\n",
      "2700 0.6931471824645996\n",
      "2800 0.6931471824645996\n",
      "2900 0.6931471824645996\n",
      "3000 0.6931471824645996\n",
      "3100 0.6931471824645996\n",
      "3200 0.6931471824645996\n",
      "3300 0.6931471824645996\n",
      "3400 0.6931471824645996\n",
      "3500 0.6931471824645996\n",
      "3600 0.6931471824645996\n",
      "3700 0.6931471824645996\n",
      "3800 0.6931471824645996\n",
      "3900 0.6931471824645996\n",
      "4000 0.6931471824645996\n",
      "4100 0.6931471824645996\n",
      "4200 0.6931471824645996\n",
      "4300 0.6931471824645996\n",
      "4400 0.6931471824645996\n",
      "4500 0.6931471824645996\n",
      "4600 0.6931471824645996\n",
      "4700 0.6931471824645996\n",
      "4800 0.6931471824645996\n",
      "4900 0.6931471824645996\n",
      "5000 0.6931471824645996\n",
      "5100 0.6931471824645996\n",
      "5200 0.6931471824645996\n",
      "5300 0.6931471824645996\n",
      "5400 0.6931471824645996\n",
      "5500 0.6931471824645996\n",
      "5600 0.6931471824645996\n",
      "5700 0.6931471824645996\n",
      "5800 0.6931471824645996\n",
      "5900 0.6931471824645996\n",
      "6000 0.6931471824645996\n",
      "6100 0.6931471824645996\n",
      "6200 0.6931471824645996\n",
      "6300 0.6931471824645996\n",
      "6400 0.6931471824645996\n",
      "6500 0.6931471824645996\n",
      "6600 0.6931471824645996\n",
      "6700 0.6931471824645996\n",
      "6800 0.6931471824645996\n",
      "6900 0.6931471824645996\n",
      "7000 0.6931471824645996\n",
      "7100 0.6931471824645996\n",
      "7200 0.6931471824645996\n",
      "7300 0.6931471824645996\n",
      "7400 0.6931471824645996\n",
      "7500 0.6931471824645996\n",
      "7600 0.6931471824645996\n",
      "7700 0.6931471824645996\n",
      "7800 0.6931471824645996\n",
      "7900 0.6931471824645996\n",
      "8000 0.6931471824645996\n",
      "8100 0.6931471824645996\n",
      "8200 0.6931471824645996\n",
      "8300 0.6931471824645996\n",
      "8400 0.6931471824645996\n",
      "8500 0.6931471824645996\n",
      "8600 0.6931471824645996\n",
      "8700 0.6931471824645996\n",
      "8800 0.6931471824645996\n",
      "8900 0.6931471824645996\n",
      "9000 0.6931471824645996\n",
      "9100 0.6931471824645996\n",
      "9200 0.6931471824645996\n",
      "9300 0.6931471824645996\n",
      "9400 0.6931471824645996\n",
      "9500 0.6931471824645996\n",
      "9600 0.6931471824645996\n",
      "9700 0.6931471824645996\n",
      "9800 0.6931471824645996\n",
      "9900 0.6931471824645996\n",
      "10000 0.6931471824645996\n"
     ]
    }
   ],
   "source": [
    "# 비용 함수와 옵티마이저 정의\n",
    "criterion = torch.nn.BCELoss().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1)\n",
    "\n",
    "for step in range(10001): \n",
    "    optimizer.zero_grad()\n",
    "    hypothesis = model(X)\n",
    "\n",
    "    # 비용 함수\n",
    "    cost = criterion(hypothesis, Y)\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if step % 100 == 0: # 100번째 에포크마다 비용 출력\n",
    "        print(step, cost.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델의 출력값(Hypothesis):  [[0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]]\n",
      "모델의 예측값(Predicted):  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "실제값(Y):  [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "정확도(Accuracy):  0.5\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    hypothesis = model(X)\n",
    "    predicted = (hypothesis > 0.5).float()\n",
    "    accuracy = (predicted == Y).float().mean()\n",
    "    print('모델의 출력값(Hypothesis): ', hypothesis.detach().cpu().numpy())\n",
    "    print('모델의 예측값(Predicted): ', predicted.detach().cpu().numpy())\n",
    "    print('실제값(Y): ', Y.cpu().numpy())\n",
    "    print('정확도(Accuracy): ', accuracy.item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이토치로 다층 퍼셉트론 구현하기\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device(\"mps\")\n",
    "torch.manual_seed(777)\n",
    "if device == 'mps':\n",
    "    torch.mps.manual_seed_all(777)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7408947944641113\n",
      "100 0.6931389570236206\n",
      "200 0.6931374073028564\n",
      "300 0.6931357383728027\n",
      "400 0.6931342482566833\n",
      "500 0.6931324601173401\n",
      "600 0.693130612373352\n",
      "700 0.6931287050247192\n",
      "800 0.6931267380714417\n",
      "900 0.6931245923042297\n",
      "1000 0.693122386932373\n",
      "1100 0.693120002746582\n",
      "1200 0.6931174993515015\n",
      "1300 0.6931146383285522\n",
      "1400 0.6931118369102478\n",
      "1500 0.6931086182594299\n",
      "1600 0.6931051015853882\n",
      "1700 0.6931012272834778\n",
      "1800 0.6930969953536987\n",
      "1900 0.6930922865867615\n",
      "2000 0.6930870413780212\n",
      "2100 0.6930812001228333\n",
      "2200 0.6930745840072632\n",
      "2300 0.6930670738220215\n",
      "2400 0.6930584907531738\n",
      "2500 0.6930485963821411\n",
      "2600 0.6930371522903442\n",
      "2700 0.6930238008499146\n",
      "2800 0.6930078268051147\n",
      "2900 0.6929886937141418\n",
      "3000 0.6929655075073242\n",
      "3100 0.6929367780685425\n",
      "3200 0.6929006576538086\n",
      "3300 0.6928542852401733\n",
      "3400 0.6927931904792786\n",
      "3500 0.6927101612091064\n",
      "3600 0.6925928592681885\n",
      "3700 0.6924186944961548\n",
      "3800 0.6921423673629761\n",
      "3900 0.6916618347167969\n",
      "4000 0.6907040476799011\n",
      "4100 0.6883158087730408\n",
      "4200 0.6790615320205688\n",
      "4300 0.5542857050895691\n",
      "4400 0.030011385679244995\n",
      "4500 0.0077390605583786964\n",
      "4600 0.00409298250451684\n",
      "4700 0.0027106506749987602\n",
      "4800 0.0020015654154121876\n",
      "4900 0.0015754884807392955\n",
      "5000 0.0012931788805872202\n",
      "5100 0.0010933788726106286\n",
      "5200 0.0009449484059587121\n",
      "5300 0.0008306210511364043\n",
      "5400 0.0007400343893095851\n",
      "5500 0.0006665753317065537\n",
      "5600 0.0006058708531782031\n",
      "5700 0.0005549216293729842\n",
      "5800 0.0005115789826959372\n",
      "5900 0.0004743062308989465\n",
      "6000 0.00044188013998791575\n",
      "6100 0.0004134951741434634\n",
      "6200 0.00038837589090690017\n",
      "6300 0.0003660299407783896\n",
      "6400 0.0003460695734247565\n",
      "6500 0.0003280474920757115\n",
      "6600 0.000311784737277776\n",
      "6700 0.0002969680936075747\n",
      "6800 0.0002835081540979445\n",
      "6900 0.00027112156385555863\n",
      "7000 0.0002597487182356417\n",
      "7100 0.00024927034974098206\n",
      "7200 0.00023956710356287658\n",
      "7300 0.00023057943326421082\n",
      "7400 0.00022220294340513647\n",
      "7500 0.00021442270372062922\n",
      "7600 0.00020713436242658645\n",
      "7700 0.00020032303291372955\n",
      "7800 0.00019389926455914974\n",
      "7900 0.00018786307191476226\n",
      "8000 0.00018218457989860326\n",
      "8100 0.00017689366359263659\n",
      "8200 0.0001718263083603233\n",
      "8300 0.00016704214795026928\n",
      "8400 0.00016254119691438973\n",
      "8500 0.00015823403373360634\n",
      "8600 0.00015415041707456112\n",
      "8700 0.00015026057371869683\n",
      "8800 0.0001465197856305167\n",
      "8900 0.00014301745977718383\n",
      "9000 0.00013964928803034127\n",
      "9100 0.00013644507271237671\n",
      "9200 0.00013336006668396294\n",
      "9300 0.0001304390316363424\n",
      "9400 0.00012760740355588496\n",
      "9500 0.00012490992958191782\n",
      "9600 0.00012230189167894423\n",
      "9700 0.00011981307034147903\n",
      "9800 0.00011739877663785592\n",
      "9900 0.00011510370677569881\n",
      "10000 0.00011288315727142617\n"
     ]
    }
   ],
   "source": [
    "# XOR 문제 풀기\n",
    "X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]]).to(device)\n",
    "Y = torch.FloatTensor([[0], [1], [1], [0]]).to(device)\n",
    "\n",
    "model = nn.Sequential(\n",
    "          nn.Linear(2, 10, bias=True), # input_layer = 2, hidden_layer1 = 10\n",
    "          nn.Sigmoid(),\n",
    "          nn.Linear(10, 10, bias=True), # hidden_layer1 = 10, hidden_layer2 = 10\n",
    "          nn.Sigmoid(),\n",
    "          nn.Linear(10, 10, bias=True), # hidden_layer2 = 10, hidden_layer3 = 10\n",
    "          nn.Sigmoid(),\n",
    "          nn.Linear(10, 1, bias=True), # hidden_layer3 = 10, output_layer = 1\n",
    "          nn.Sigmoid()\n",
    "          ).to(device)\n",
    "\n",
    "criterion = torch.nn.BCELoss().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1)  # modified learning rate from 0.1 to 1\n",
    "\n",
    "for epoch in range(10001):\n",
    "    optimizer.zero_grad()\n",
    "    # forward 연산\n",
    "    hypothesis = model(X)\n",
    "\n",
    "    # 비용 함수\n",
    "    cost = criterion(hypothesis, Y)\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 100의 배수에 해당되는 에포크마다 비용을 출력\n",
    "    if epoch % 100 == 0:\n",
    "        print(epoch, cost.item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델의 출력값(Hypothesis):  [[6.8903209e-05]\n",
      " [9.9988174e-01]\n",
      " [9.9989259e-01]\n",
      " [1.5691217e-04]]\n",
      "모델의 예측값(Predicted):  [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "실제값(Y):  [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "정확도(Accuracy):  1.0\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    hypothesis = model(X)\n",
    "    predicted = (hypothesis > 0.5).float()\n",
    "    accuracy = (predicted == Y).float().mean()\n",
    "    print('모델의 출력값(Hypothesis): ', hypothesis.detach().cpu().numpy())\n",
    "    print('모델의 예측값(Predicted): ', predicted.detach().cpu().numpy())\n",
    "    print('실제값(Y): ', Y.cpu().numpy())\n",
    "    print('정확도(Accuracy): ', accuracy.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 역전파(Backpropagation)\n",
    "- W = W -a(del_E/del_W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 다층 퍼셉트론으로 손글씨 분류하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  5. 13.  9.  1.  0.  0.]\n",
      " [ 0.  0. 13. 15. 10. 15.  5.  0.]\n",
      " [ 0.  3. 15.  2.  0. 11.  8.  0.]\n",
      " [ 0.  4. 12.  0.  0.  8.  8.  0.]\n",
      " [ 0.  5.  8.  0.  0.  9.  8.  0.]\n",
      " [ 0.  4. 11.  0.  1. 12.  7.  0.]\n",
      " [ 0.  2. 14.  5. 10. 12.  0.  0.]\n",
      " [ 0.  0.  6. 13. 10.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt # 시각화를 위한 맷플롯립\n",
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits() # 1,979개의 이미지 데이터 로드\n",
    "print(digits.images[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "images_and_labels = list(zip(digits.images, digits.target))\n",
    "for index, (image, label) in enumerate(images_and_labels[:5]): # 5개의 샘플만 출력\n",
    "    plt.subplot(2, 5, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('sample: %i' % label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/08/7nssmq351bs05px0mvs17chr0000gn/T/ipykernel_87933/3402289056.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(X, dtype=torch.float32)\n",
      "/var/folders/08/7nssmq351bs05px0mvs17chr0000gn/T/ipykernel_87933/3402289056.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y = torch.tensor(Y, dtype=torch.int64)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "\n",
    "# 모델 정의: 순차적인 레이어 구조\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(64, 32), # 입력층: 64, 첫 번째 은닉층: 32\n",
    "    nn.ReLU(),         # 활성화 함수: ReLU\n",
    "    nn.Linear(32, 16), # 첫 번째 은닉층: 32, 두 번째 은닉층: 16\n",
    "    nn.ReLU(),         # 활성화 함수: ReLU\n",
    "    nn.Linear(16, 10)  # 두 번째 은닉층: 16, 출력층: 10 (클래스의 개수)\n",
    ")\n",
    "\n",
    "# 입력 데이터 X와 레이블 Y를 텐서로 변환\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "Y = torch.tensor(Y, dtype=torch.int64)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss() # 이 비용 함수는 소프트맥스 함수를 포함하고 있음.\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "losses = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "linear(): input and weight.T shapes cannot be multiplied (4x2 and 64x32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m):\n\u001b[1;32m      3\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()      \u001b[38;5;66;03m# 옵티마이저의 기울기 초기화\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m          \u001b[38;5;66;03m# 순전파 연산으로 예측값 계산\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(y_pred, Y)  \u001b[38;5;66;03m# 손실 함수로 비용 계산\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()            \u001b[38;5;66;03m# 역전파 연산으로 기울기 계산\u001b[39;00m\n",
      "File \u001b[0;32m~/AI_project/ai_venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/AI_project/ai_venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/AI_project/ai_venv/lib/python3.11/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/AI_project/ai_venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/AI_project/ai_venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/AI_project/ai_venv/lib/python3.11/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: linear(): input and weight.T shapes cannot be multiplied (4x2 and 64x32)"
     ]
    }
   ],
   "source": [
    "# 총 100번의 에포크 동안 모델 학습\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()      # 옵티마이저의 기울기 초기화\n",
    "    y_pred = model(X)          # 순전파 연산으로 예측값 계산\n",
    "    loss = loss_fn(y_pred, Y)  # 손실 함수로 비용 계산\n",
    "    loss.backward()            # 역전파 연산으로 기울기 계산\n",
    "    optimizer.step()           # 옵티마이저를 통해 파라미터 업데이트\n",
    "\n",
    "    # 10번째 에포크마다 현재 에포크와 손실 값 출력\n",
    "    if epoch % 10 == 0:\n",
    "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
    "                epoch, 100, loss.item()\n",
    "            ))\n",
    "\n",
    "    # 손실 값을 리스트에 추가하여 추적\n",
    "    losses.append(loss.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 다층 퍼셉트론으로 손글씨 분류하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# % matplotlib inline\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "mnist = fetch_openml('mnist_784', version=1, cache=True, as_frame=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist.target = mnist.target.astype(np.int8)\n",
    "X = mnist.data / 255  # 0-255값을 [0,1] 구간으로 정규화\n",
    "y = mnist.target\n",
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
