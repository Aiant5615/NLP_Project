{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 소프트맥스 회귀의 비용 함수 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0900, 0.2447, 0.6652])\n",
      "tensor([[0.2645, 0.1639, 0.1855, 0.2585, 0.1277],\n",
      "        [0.2430, 0.1624, 0.2322, 0.1930, 0.1694],\n",
      "        [0.2226, 0.1986, 0.2326, 0.1594, 0.1868]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0, 2, 1])\n",
      "tensor([[0],\n",
      "        [2],\n",
      "        [1]])\n",
      "tensor([[1., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0., 0.]])\n",
      "tensor(1.4689, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "torch.manual_seed(1)\n",
    "\n",
    "z = torch.FloatTensor([1, 2, 3])\n",
    "hypothesis = F.softmax(z, dim=0)\n",
    "print(hypothesis)\n",
    "\n",
    "hypothesis.sum()\n",
    "z = torch.rand(3, 5, requires_grad=True)\n",
    "hypothesis = F.softmax(z, dim=1)\n",
    "print(hypothesis)\n",
    "\n",
    "y = torch.randint(5, (3,)).long()\n",
    "print(y)\n",
    "\n",
    "# 모든 원소가 0의 값을 가진 3 × 5 텐서 생성\n",
    "y_one_hot = torch.zeros_like(hypothesis) \n",
    "y_one_hot.scatter_(1, y.unsqueeze(1), 1)\n",
    "\n",
    "print(y.unsqueeze(1))\n",
    "\n",
    "print(y_one_hot)\n",
    "\n",
    "cost = (y_one_hot * -torch.log(hypothesis)).sum(dim=1).mean()\n",
    "print(cost)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3301, -1.8084, -1.6846, -1.3530, -2.0584],\n",
       "        [-1.4147, -1.8174, -1.4602, -1.6450, -1.7758],\n",
       "        [-1.5025, -1.6165, -1.4586, -1.8360, -1.6776]],\n",
       "       grad_fn=<LogSoftmaxBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Low level\n",
    "torch.log(F.softmax(z, dim=1))\n",
    "\n",
    "# High level\n",
    "F.log_softmax(z, dim=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.4689, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Low level\n",
    "# 첫번째 수식\n",
    "(y_one_hot * -torch.log(F.softmax(z, dim=1))).sum(dim=1).mean()\n",
    "# 두번째 수식\n",
    "(y_one_hot * - F.log_softmax(z, dim=1)).sum(dim=1).mean()\n",
    "\n",
    "# High level\n",
    "# 세번째 수식\n",
    "F.nll_loss(F.log_softmax(z, dim=1), y)\n",
    "# 여기서 nll이란 Negative Log Likelihood의 약자입니다. \n",
    "\n",
    "# 네번째 수식\n",
    "F.cross_entropy(z, y)\n",
    "## 중요: F.cross_entropy는 비용 함수에 소프트맥스 함수까지 포함하고 있음을 기억하고 있어야 구현 시 혼동하지 않습니다.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 소프트맥스 회귀 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10e2dedb0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "torch.manual_seed(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = [[1, 2, 1, 1],\n",
    "           [2, 1, 3, 2],\n",
    "           [3, 1, 3, 4],\n",
    "           [4, 1, 5, 5],\n",
    "           [1, 7, 5, 5],\n",
    "           [1, 2, 5, 6],\n",
    "           [1, 6, 6, 6],\n",
    "           [1, 7, 7, 7]]\n",
    "y_train = [2, 2, 2, 1, 1, 1, 0, 0]\n",
    "x_train = torch.FloatTensor(x_train)\n",
    "y_train = torch.LongTensor(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3])\n"
     ]
    }
   ],
   "source": [
    "y_one_hot = torch.zeros(8, 3)\n",
    "y_one_hot.scatter_(1, y_train.unsqueeze(1), 1)\n",
    "print(y_one_hot.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 초기화\n",
    "W = torch.zeros((4, 3), requires_grad=True)\n",
    "b = torch.zeros((1, 3), requires_grad=True)\n",
    "# optimizer 설정\n",
    "optimizer = optim.SGD([W, b], lr=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000 Cost: 1.098612\n",
      "Epoch  100/1000 Cost: 0.704200\n",
      "Epoch  200/1000 Cost: 0.622999\n",
      "Epoch  300/1000 Cost: 0.565717\n",
      "Epoch  400/1000 Cost: 0.515291\n",
      "Epoch  500/1000 Cost: 0.467662\n",
      "Epoch  600/1000 Cost: 0.421278\n",
      "Epoch  700/1000 Cost: 0.375402\n",
      "Epoch  800/1000 Cost: 0.329766\n",
      "Epoch  900/1000 Cost: 0.285073\n",
      "Epoch 1000/1000 Cost: 0.248155\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 1000\n",
    "for epoch in range(nb_epochs + 1):\n",
    "\n",
    "    # 가설\n",
    "    hypothesis = F.softmax(x_train.matmul(W) + b, dim=1) \n",
    "    \n",
    "\n",
    "    # 비용 함수\n",
    "    cost = (y_one_hot * -torch.log(hypothesis)).sum(dim=1).mean()\n",
    "\n",
    "    # cost로 H(x) 개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 100번마다 로그 출력\n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
    "            epoch, nb_epochs, cost.item()\n",
    "        ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000 Cost: 1.098612\n",
      "Epoch  100/1000 Cost: 0.704200\n",
      "Epoch  200/1000 Cost: 0.622999\n",
      "Epoch  300/1000 Cost: 0.565717\n",
      "Epoch  400/1000 Cost: 0.515292\n",
      "Epoch  500/1000 Cost: 0.467662\n",
      "Epoch  600/1000 Cost: 0.421278\n",
      "Epoch  700/1000 Cost: 0.375401\n",
      "Epoch  800/1000 Cost: 0.329765\n",
      "Epoch  900/1000 Cost: 0.285073\n",
      "Epoch 1000/1000 Cost: 0.248155\n"
     ]
    }
   ],
   "source": [
    "# 소프트 맥스 회귀 구현하기 (하이-레벨)\n",
    "#  F.cross_entropy()를 사용하여 비용 함수를 구현\n",
    "# F.cross_entropy()는 그 자체로 소프트 맥스 함수를 포함하고 있음\n",
    "\n",
    "# 모델 초기화\n",
    "W = torch.zeros((4, 3), requires_grad=True)\n",
    "b = torch.zeros((1, 3), requires_grad=True)\n",
    "# optimizer 설정\n",
    "optimizer = optim.SGD([W, b], lr=0.1)\n",
    "\n",
    "nb_epochs = 1000\n",
    "for epoch in range(nb_epochs + 1):\n",
    "\n",
    "    # Cost 계산\n",
    "    z = x_train.matmul(W) + b\n",
    "    cost = F.cross_entropy(z, y_train)\n",
    "\n",
    "    # cost로 H(x) 개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 100번마다 로그 출력\n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
    "            epoch, nb_epochs, cost.item()\n",
    "        ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000 Cost: 1.616785\n",
      "Epoch  100/1000 Cost: 0.658891\n",
      "Epoch  200/1000 Cost: 0.573443\n",
      "Epoch  300/1000 Cost: 0.518151\n",
      "Epoch  400/1000 Cost: 0.473265\n",
      "Epoch  500/1000 Cost: 0.433516\n",
      "Epoch  600/1000 Cost: 0.396563\n",
      "Epoch  700/1000 Cost: 0.360914\n",
      "Epoch  800/1000 Cost: 0.325392\n",
      "Epoch  900/1000 Cost: 0.289178\n",
      "Epoch 1000/1000 Cost: 0.254148\n"
     ]
    }
   ],
   "source": [
    "# 소프트맥스 회귀 nn.Module로 구현하기\n",
    "\n",
    "# 모델을 선언 및 초기화. 4개의 특성을 가지고 3개의 클래스로 분류. input_dim=4, output_dim=3.\n",
    "model = nn.Linear(4, 3)\n",
    "\n",
    "# optimizer 설정\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "nb_epochs = 1000\n",
    "for epoch in range(nb_epochs + 1):\n",
    "\n",
    "    # H(x) 계산\n",
    "    prediction = model(x_train)\n",
    "\n",
    "    # cost 계산\n",
    "    cost = F.cross_entropy(prediction, y_train)\n",
    "\n",
    "    # cost로 H(x) 개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 20번마다 로그 출력\n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
    "            epoch, nb_epochs, cost.item()\n",
    "        ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000 Cost: 2.637636\n",
      "Epoch  100/1000 Cost: 0.647903\n",
      "Epoch  200/1000 Cost: 0.564643\n",
      "Epoch  300/1000 Cost: 0.511043\n",
      "Epoch  400/1000 Cost: 0.467249\n",
      "Epoch  500/1000 Cost: 0.428281\n",
      "Epoch  600/1000 Cost: 0.391924\n",
      "Epoch  700/1000 Cost: 0.356742\n",
      "Epoch  800/1000 Cost: 0.321577\n",
      "Epoch  900/1000 Cost: 0.285617\n",
      "Epoch 1000/1000 Cost: 0.250818\n"
     ]
    }
   ],
   "source": [
    "# 소프트맥스 회귀 클래스로 구현하기\n",
    "\n",
    "class SoftmaxClassifierModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(4, 3) # Output이 3!\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "model = SoftmaxClassifierModel()\n",
    "\n",
    "# optimizer 설정\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "nb_epochs = 1000\n",
    "for epoch in range(nb_epochs + 1):\n",
    "\n",
    "    # H(x) 계산\n",
    "    prediction = model(x_train)\n",
    "\n",
    "    # cost 계산\n",
    "    cost = F.cross_entropy(prediction, y_train)\n",
    "\n",
    "    # cost로 H(x) 개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 20번마다 로그 출력\n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
    "            epoch, nb_epochs, cost.item()\n",
    "        ))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 소프트맥스 회귀로 MNIST 데이터 분류하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다음 기기로 학습합니다: cpu\n"
     ]
    }
   ],
   "source": [
    "USE_CUDA = torch.cuda.is_available() # GPU를 사용가능하면 True, 아니라면 False를 리턴\n",
    "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\") # GPU 사용 가능하면 사용하고 아니면 CPU 사용\n",
    "print(\"다음 기기로 학습합니다:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS 장치를 지원하도록 build가 되었는가? True\n",
      "MPS 장치가 사용 가능한가? True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"MPS 장치를 지원하도록 build가 되었는가? {torch.backends.mps.is_built()}\")\n",
    "print(f\"MPS 장치가 사용 가능한가? {torch.backends.mps.is_available()}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 사용 중인 장치: mps\n"
     ]
    }
   ],
   "source": [
    "print(f\"현재 사용 중인 장치: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reproducibility\n",
    "random.seed(777)\n",
    "torch.manual_seed(777)\n",
    "if device == 'mps':\n",
    "    torch.mps.manual_seed_all(777)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "training_epochs = 15\n",
    "batch_size = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:09<00:00, 1050748.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz to MNIST_data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 123047.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:01<00:00, 1052451.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz to MNIST_data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 221809.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# MNIST dataset\n",
    "mnist_train = dsets.MNIST(root='MNIST_data/',\n",
    "                          train=True,\n",
    "                          transform=transforms.ToTensor(),\n",
    "                          download=True)\n",
    "\n",
    "mnist_test = dsets.MNIST(root='MNIST_data/',\n",
    "                         train=False,\n",
    "                         transform=transforms.ToTensor(),\n",
    "                         download=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset loader\n",
    "data_loader = DataLoader(dataset=mnist_train,\n",
    "                                          batch_size=batch_size, # 배치 크기는 100\n",
    "                                          shuffle=True,\n",
    "                                          drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST data image of shape 28 * 28 = 784\n",
    "linear = nn.Linear(784, 10, bias=True).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비용 함수와 옵티마이저 정의\n",
    "criterion = nn.CrossEntropyLoss().to(device) # 내부적으로 소프트맥스 함수를 포함하고 있음.\n",
    "optimizer = torch.optim.SGD(linear.parameters(), lr=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 0.535150588\n",
      "Epoch: 0002 cost = 0.359577715\n",
      "Epoch: 0003 cost = 0.331264228\n",
      "Epoch: 0004 cost = 0.316404700\n",
      "Epoch: 0005 cost = 0.307107002\n",
      "Epoch: 0006 cost = 0.300456524\n",
      "Epoch: 0007 cost = 0.294933408\n",
      "Epoch: 0008 cost = 0.290956169\n",
      "Epoch: 0009 cost = 0.287074089\n",
      "Epoch: 0010 cost = 0.284515619\n",
      "Epoch: 0011 cost = 0.281914055\n",
      "Epoch: 0012 cost = 0.279526889\n",
      "Epoch: 0013 cost = 0.277636588\n",
      "Epoch: 0014 cost = 0.275874764\n",
      "Epoch: 0015 cost = 0.274422765\n",
      "Learning finished\n"
     ]
    }
   ],
   "source": [
    "# 학습하기\n",
    "for epoch in range(training_epochs): # 앞서 training_epochs의 값은 15로 지정함.\n",
    "    avg_cost = 0\n",
    "    total_batch = len(data_loader)\n",
    "\n",
    "    for X, Y in data_loader:\n",
    "        # 배치 크기가 100이므로 아래의 연산에서 X는 (100, 784)의 텐서가 된다.\n",
    "        X = X.view(-1, 28 * 28).to(device)\n",
    "        # 레이블은 원-핫 인코딩이 된 상태가 아니라 0 ~ 9의 정수.\n",
    "        Y = Y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = linear(X)\n",
    "        cost = criterion(hypothesis, Y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_cost += cost / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning finished')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8883000016212463\n",
      "Label:  5\n",
      "Prediction:  5\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#평가하기\n",
    "# 테스트 데이터를 사용하여 모델을 테스트한다.\n",
    "with torch.no_grad(): # torch.no_grad()를 하면 gradient 계산을 수행하지 않는다.\n",
    "    X_test = mnist_test.test_data.view(-1, 28 * 28).float().to(device)\n",
    "    Y_test = mnist_test.test_labels.to(device)\n",
    "\n",
    "    prediction = linear(X_test)\n",
    "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print('Accuracy:', accuracy.item())\n",
    "\n",
    "    # MNIST 테스트 데이터에서 무작위로 하나를 뽑아서 예측을 해본다\n",
    "    r = random.randint(0, len(mnist_test) - 1)\n",
    "    X_single_data = mnist_test.test_data[r:r + 1].view(-1, 28 * 28).float().to(device)\n",
    "    Y_single_data = mnist_test.test_labels[r:r + 1].to(device)\n",
    "\n",
    "    print('Label: ', Y_single_data.item())\n",
    "    single_prediction = linear(X_single_data)\n",
    "    print('Prediction: ', torch.argmax(single_prediction, 1).item())\n",
    "\n",
    "    plt.imshow(mnist_test.test_data[r:r + 1].view(28, 28), cmap='Greys', interpolation='nearest')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
